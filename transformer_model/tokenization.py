def tokenize(text):
    """
    Tokenizes ext from a string into a list of strings
    """
    return text.split()